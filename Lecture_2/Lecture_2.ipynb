{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework Lecture 3\n",
    "\n",
    "### 1.0 Setup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Python packages\n",
    "%matplotlib inline  \n",
    "import pandas as pd \n",
    "import numpy as np  \n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "import statsmodels.api as sm\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [10,8]  # Set default figure size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2.0 Data\n",
    "\n",
    "To change things up, I downloaded a house price data set from [Kaggle.com](https://www.kaggle.com/ \"Kaggle.com\"). Kaggle regularly hosts machine learning competitions and also offers many free data sets provided by the community. For this lecture I chose the [Melbourne Housing Market](https://www.kaggle.com/anthonypino/melbourne-housing-market?select=Melbourne_housing_FULL.csv \"Kaggledta.com\") dataset. You can find a detailed description of it by clicking the link. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the Melbourne Housing data set\n",
    "housing_raw = pd.read_csv('Melbourne_housing_FULL.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select a subset of a couple of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Bedroom2</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Car</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>Distance</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1035000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>-37.80790</td>\n",
       "      <td>144.99340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>-37.80930</td>\n",
       "      <td>144.99440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1600000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>-37.80720</td>\n",
       "      <td>144.99410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1876000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1910.0</td>\n",
       "      <td>-37.80240</td>\n",
       "      <td>144.99930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1636000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>-37.80600</td>\n",
       "      <td>144.99540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34847</th>\n",
       "      <td>500000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>25.5</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>-37.61940</td>\n",
       "      <td>145.03951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34849</th>\n",
       "      <td>570000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>404.0</td>\n",
       "      <td>25.5</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>-37.61031</td>\n",
       "      <td>145.03393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34853</th>\n",
       "      <td>888000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>-37.81551</td>\n",
       "      <td>144.88826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34854</th>\n",
       "      <td>705000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>-37.82286</td>\n",
       "      <td>144.87856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34856</th>\n",
       "      <td>1020000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1930.0</td>\n",
       "      <td>-37.81810</td>\n",
       "      <td>144.89351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10459 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Price  Rooms  Bedroom2  Bathroom  Car  Landsize  Distance  \\\n",
       "2      1035000.0      2       2.0       1.0  0.0     156.0       2.5   \n",
       "4      1465000.0      3       3.0       2.0  0.0     134.0       2.5   \n",
       "6      1600000.0      4       3.0       1.0  2.0     120.0       2.5   \n",
       "11     1876000.0      3       4.0       2.0  0.0     245.0       2.5   \n",
       "14     1636000.0      2       2.0       1.0  2.0     256.0       2.5   \n",
       "...          ...    ...       ...       ...  ...       ...       ...   \n",
       "34847   500000.0      3       3.0       2.0  2.0     383.0      25.5   \n",
       "34849   570000.0      3       3.0       2.0  2.0     404.0      25.5   \n",
       "34853   888000.0      2       2.0       2.0  1.0      98.0       6.3   \n",
       "34854   705000.0      2       2.0       1.0  2.0     220.0       6.3   \n",
       "34856  1020000.0      2       2.0       1.0  0.0     250.0       6.3   \n",
       "\n",
       "       YearBuilt  Lattitude  Longtitude  \n",
       "2         1900.0  -37.80790   144.99340  \n",
       "4         1900.0  -37.80930   144.99440  \n",
       "6         2014.0  -37.80720   144.99410  \n",
       "11        1910.0  -37.80240   144.99930  \n",
       "14        1890.0  -37.80600   144.99540  \n",
       "...          ...        ...         ...  \n",
       "34847     2016.0  -37.61940   145.03951  \n",
       "34849     2012.0  -37.61031   145.03393  \n",
       "34853     2018.0  -37.81551   144.88826  \n",
       "34854     2000.0  -37.82286   144.87856  \n",
       "34856     1930.0  -37.81810   144.89351  \n",
       "\n",
       "[10459 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select a subset of variables\n",
    "housing = housing_raw[['Price','Rooms','Bedroom2','Bathroom','Car','Landsize','Distance','YearBuilt'\n",
    "                       ,'Lattitude','Longtitude']]\n",
    "\n",
    "# drop rows with missing values\n",
    "housing = housing.dropna()\n",
    "housing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0 Bootstrap\n",
    "\n",
    "**You can ignore section 3.1 and jump to the implementation with `statsmodels` in section 3.2.**\n",
    " \n",
    "### 3.1 Implementation with own Code\n",
    " \n",
    "\n",
    "Recall that we built a nice \"OLS\" class last week that allows us to conduct OLS regressions and produces regression output for any data we want. Instead of writing code from scratch, let's simply add a bootstrap option to it.\n",
    "\n",
    "#### 3.1.1 Adjusting the `class`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OLS:\n",
    "\n",
    "    \"\"\"\n",
    "    This code implements a simple OLS regression. The inputs Y and X must be in numpy matrix format. \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, Y, X):\n",
    "        #Initialize the dependent and independent variables\n",
    "        self.Y, self.X = Y, X \n",
    "        \n",
    "        # terminate and produce error message, if Y or X are of wrong type\n",
    "        if isinstance(X,np.ndarray) == False:\n",
    "            raise TypeError('X is not a numpy ndarray!')\n",
    "        if isinstance(Y,np.ndarray) == False:\n",
    "            raise TypeError('Y is not a numpy ndarray!')\n",
    "    \n",
    "    # here I moved the actual regression into its own function to streamline the bootstrap code\n",
    "    def get_betas(self, YY, XX):\n",
    "        \n",
    "        #Estimate the beta coefficients\n",
    "        return np.linalg.inv(XX.T @ XX) @ (XX.T @ YY)\n",
    "    \n",
    "    \n",
    "    def estimate(self, se_method = 'standard', B = 1000):\n",
    "        \n",
    "        #unpack Y and X\n",
    "        Y, X = self.Y, self.X\n",
    "        \n",
    "        # If not input is given, we simply use standard standard errors. It is useful to also print a message to \n",
    "        # to make users aware of the standard_errors used\n",
    "        print(\"Standard Errors computed using method:\", se_method)\n",
    "        \n",
    "        # run the OLS regression by calling the get_betas() function\n",
    "        self.beta = self.get_betas(Y, X)\n",
    "        \n",
    "        # ------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        if se_method == 'standard':\n",
    "            #compute the regression residuals\n",
    "            eps = Y - X @ self.beta\n",
    "        \n",
    "            #compute the residual variance\n",
    "            s_hat = 1/(Y.shape[0] - self.beta.shape[0]) * eps.T @ eps\n",
    "            \n",
    "            #compute the standard errors\n",
    "            self.se = np.sqrt(np.diag(np.linalg.inv(X.T @ X) * s_hat.item())).reshape((self.beta.shape[0],1))\n",
    "            \n",
    "            #compute confidence intervals\n",
    "            CI_upper = self.beta + stats.norm.ppf(0.975)*self.se\n",
    "            CI_lower = self.beta - stats.norm.ppf(0.975)*self.se\n",
    "        \n",
    "        elif se_method == 'bootstrap':\n",
    "            print(\"Number of Bootstrap samples:\", B)\n",
    "            \n",
    "            # initialize the array of bootstrap estimates\n",
    "            self.bootstrapbeta = np.empty([self.beta.shape[0],B])\n",
    "            \n",
    "            # compute the coefficients over the bootstrap sample\n",
    "            for i in range(B):\n",
    "                \n",
    "                # generate a vector of randomly drawn indices with replacement\n",
    "                random_indices = np.random.choice(Y.shape[0], size=Y.shape[0], replace=True)\n",
    "                \n",
    "                # select the corresponding rows of Y and X\n",
    "                Y_b = Y[random_indices]\n",
    "                X_b = X[random_indices]\n",
    "                \n",
    "                # compute the regression coefficients for the bootstrap samples\n",
    "                beta = self.get_betas(Y_b, X_b)\n",
    "                \n",
    "                # collect all bootstrap coefficients\n",
    "                self.bootstrapbeta[:,i] = beta.ravel()\n",
    "                \n",
    "            # compute bootstrap standard errors\n",
    "            self.se = np.sqrt(np.mean(np.square(self.bootstrapbeta-self.beta),axis=1)).reshape((self.beta.shape[0],1))\n",
    "        \n",
    "            #compute the bootstrap confidence intervals\n",
    "            CI_upper = self.beta + 2*self.se\n",
    "            CI_lower = self.beta - 2*self.se\n",
    "        \n",
    "        # ------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        #compute t-statistic for standard hypothesis test\n",
    "        t = np.abs(self.beta/self.se)\n",
    "\n",
    "        #compute p-values for standard hypothesis test\n",
    "        p_vals = 2*(1-stats.norm.cdf(np.abs(t)))\n",
    "        \n",
    "        #generate an output table\n",
    "        outmat = np.concatenate((self.beta,self.se,t,p_vals,CI_lower,CI_upper),axis=1)\n",
    "        table = pd.DataFrame(outmat)\n",
    "        table.columns =['beta', 'se','t-statistic','p-value','CI - lower','CI - upper'] \n",
    "        \n",
    "        return table\n",
    "    \n",
    "    def hypothesis_test(self,i,β_0):\n",
    "        # here a small if statement tests whether estimates have been computed before. If not, we simply call the\n",
    "        # \"estimate\" function of our class\n",
    "        if hasattr(self, 'beta'):\n",
    "            beta, se = self.beta, self.se\n",
    "            print(\"Previous estimates available. Hypothesis test is conducted based on previous estimates.\")\n",
    "        else:\n",
    "            self.estimate()\n",
    "            beta, se = self.beta, self.se\n",
    "            print(\"No previous estimates available. Estimating OLS to obtain coefficients.\")\n",
    "        \n",
    "        \n",
    "        # compute the test statistic\n",
    "        t = np.abs((beta[i] - β_0)/se.T[i])\n",
    "        \n",
    "        #compute p-values\n",
    "        p_vals = 2*(1-stats.norm.cdf(np.abs(t)))\n",
    "        \n",
    "        # create output table\n",
    "        outmat = np.concatenate((t,p_vals),axis=1)\n",
    "        table = pd.DataFrame(outmat)\n",
    "        table.columns =['t-statistic','p-value']\n",
    "        \n",
    "        return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having extended the functionality of our OLS class in such a way, we can again specify OLS objects and call OLS class functions on them. In our case, this allows us to easily compute standard errors in standard fashion or using bootstrap. Given that we also specified default input arguments and have the class print messages, it is also fairly robust to user error. \n",
    "\n",
    "Let's now use it on our house price dataset:\n",
    "\n",
    "#### 3.1.2 Estimating the regression with non-robust standard errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the Y, and X matrices\n",
    "Y = np.asarray([housing.Price]).T\n",
    "X = np.asarray(housing.iloc[:,1:])\n",
    "\n",
    "# add a constant to the independent variables\n",
    "X = np.hstack((np.ones([X.shape[0],1]), X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the house price regression object\n",
    "HP_reg = OLS(Y,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Errors computed using method: standard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beta</th>\n",
       "      <th>se</th>\n",
       "      <th>t-statistic</th>\n",
       "      <th>p-value</th>\n",
       "      <th>CI - lower</th>\n",
       "      <th>CI - upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.542411e+08</td>\n",
       "      <td>5.662622e+06</td>\n",
       "      <td>27.238469</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.653397e+08</td>\n",
       "      <td>-1.431426e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.187334e+05</td>\n",
       "      <td>1.770405e+04</td>\n",
       "      <td>12.354990</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.840341e+05</td>\n",
       "      <td>2.534327e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.218366e+04</td>\n",
       "      <td>1.775590e+04</td>\n",
       "      <td>1.249369</td>\n",
       "      <td>2.115303e-01</td>\n",
       "      <td>-1.261726e+04</td>\n",
       "      <td>5.698457e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.742361e+05</td>\n",
       "      <td>8.392414e+03</td>\n",
       "      <td>32.676667</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.577873e+05</td>\n",
       "      <td>2.906849e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.902475e+04</td>\n",
       "      <td>5.082994e+03</td>\n",
       "      <td>13.579547</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.906226e+04</td>\n",
       "      <td>7.898723e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.050285e+01</td>\n",
       "      <td>4.093579e+00</td>\n",
       "      <td>7.451389</td>\n",
       "      <td>9.237056e-14</td>\n",
       "      <td>2.247958e+01</td>\n",
       "      <td>3.852611e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-3.415782e+04</td>\n",
       "      <td>7.586077e+02</td>\n",
       "      <td>45.026992</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-3.564467e+04</td>\n",
       "      <td>-3.267098e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-4.969205e+03</td>\n",
       "      <td>1.338045e+02</td>\n",
       "      <td>37.137808</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-5.231457e+03</td>\n",
       "      <td>-4.706953e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.269495e+06</td>\n",
       "      <td>5.312626e+04</td>\n",
       "      <td>23.895812</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.373621e+06</td>\n",
       "      <td>-1.165370e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8.011514e+05</td>\n",
       "      <td>4.103273e+04</td>\n",
       "      <td>19.524693</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.207288e+05</td>\n",
       "      <td>8.815741e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           beta            se  t-statistic       p-value    CI - lower  \\\n",
       "0 -1.542411e+08  5.662622e+06    27.238469  0.000000e+00 -1.653397e+08   \n",
       "1  2.187334e+05  1.770405e+04    12.354990  0.000000e+00  1.840341e+05   \n",
       "2  2.218366e+04  1.775590e+04     1.249369  2.115303e-01 -1.261726e+04   \n",
       "3  2.742361e+05  8.392414e+03    32.676667  0.000000e+00  2.577873e+05   \n",
       "4  6.902475e+04  5.082994e+03    13.579547  0.000000e+00  5.906226e+04   \n",
       "5  3.050285e+01  4.093579e+00     7.451389  9.237056e-14  2.247958e+01   \n",
       "6 -3.415782e+04  7.586077e+02    45.026992  0.000000e+00 -3.564467e+04   \n",
       "7 -4.969205e+03  1.338045e+02    37.137808  0.000000e+00 -5.231457e+03   \n",
       "8 -1.269495e+06  5.312626e+04    23.895812  0.000000e+00 -1.373621e+06   \n",
       "9  8.011514e+05  4.103273e+04    19.524693  0.000000e+00  7.207288e+05   \n",
       "\n",
       "     CI - upper  \n",
       "0 -1.431426e+08  \n",
       "1  2.534327e+05  \n",
       "2  5.698457e+04  \n",
       "3  2.906849e+05  \n",
       "4  7.898723e+04  \n",
       "5  3.852611e+01  \n",
       "6 -3.267098e+04  \n",
       "7 -4.706953e+03  \n",
       "8 -1.165370e+06  \n",
       "9  8.815741e+05  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# estimate a regression with standard standard errors\n",
    "HP_reg.estimate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.3 Estimating the regression with Bootstrap standard errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Errors computed using method: bootstrap\n",
      "Number of Bootstrap samples: 1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beta</th>\n",
       "      <th>se</th>\n",
       "      <th>t-statistic</th>\n",
       "      <th>p-value</th>\n",
       "      <th>CI - lower</th>\n",
       "      <th>CI - upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.542411e+08</td>\n",
       "      <td>5.935885e+06</td>\n",
       "      <td>25.984526</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.661129e+08</td>\n",
       "      <td>-1.423694e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.187334e+05</td>\n",
       "      <td>3.321442e+04</td>\n",
       "      <td>6.585494</td>\n",
       "      <td>4.533751e-11</td>\n",
       "      <td>1.523045e+05</td>\n",
       "      <td>2.851622e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.218366e+04</td>\n",
       "      <td>3.185383e+04</td>\n",
       "      <td>0.696421</td>\n",
       "      <td>4.861655e-01</td>\n",
       "      <td>-4.152399e+04</td>\n",
       "      <td>8.589131e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.742361e+05</td>\n",
       "      <td>1.436979e+04</td>\n",
       "      <td>19.084214</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.454965e+05</td>\n",
       "      <td>3.029757e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.902475e+04</td>\n",
       "      <td>6.811783e+03</td>\n",
       "      <td>10.133139</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.540118e+04</td>\n",
       "      <td>8.264832e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.050285e+01</td>\n",
       "      <td>6.513893e+00</td>\n",
       "      <td>4.682737</td>\n",
       "      <td>2.830702e-06</td>\n",
       "      <td>1.747506e+01</td>\n",
       "      <td>4.353063e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-3.415782e+04</td>\n",
       "      <td>1.043883e+03</td>\n",
       "      <td>32.721883</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-3.624559e+04</td>\n",
       "      <td>-3.207006e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-4.969205e+03</td>\n",
       "      <td>3.006504e+02</td>\n",
       "      <td>16.528185</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-5.570506e+03</td>\n",
       "      <td>-4.367904e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.269495e+06</td>\n",
       "      <td>4.753209e+04</td>\n",
       "      <td>26.708173</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.364559e+06</td>\n",
       "      <td>-1.174431e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8.011514e+05</td>\n",
       "      <td>3.879750e+04</td>\n",
       "      <td>20.649562</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.235564e+05</td>\n",
       "      <td>8.787464e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           beta            se  t-statistic       p-value    CI - lower  \\\n",
       "0 -1.542411e+08  5.935885e+06    25.984526  0.000000e+00 -1.661129e+08   \n",
       "1  2.187334e+05  3.321442e+04     6.585494  4.533751e-11  1.523045e+05   \n",
       "2  2.218366e+04  3.185383e+04     0.696421  4.861655e-01 -4.152399e+04   \n",
       "3  2.742361e+05  1.436979e+04    19.084214  0.000000e+00  2.454965e+05   \n",
       "4  6.902475e+04  6.811783e+03    10.133139  0.000000e+00  5.540118e+04   \n",
       "5  3.050285e+01  6.513893e+00     4.682737  2.830702e-06  1.747506e+01   \n",
       "6 -3.415782e+04  1.043883e+03    32.721883  0.000000e+00 -3.624559e+04   \n",
       "7 -4.969205e+03  3.006504e+02    16.528185  0.000000e+00 -5.570506e+03   \n",
       "8 -1.269495e+06  4.753209e+04    26.708173  0.000000e+00 -1.364559e+06   \n",
       "9  8.011514e+05  3.879750e+04    20.649562  0.000000e+00  7.235564e+05   \n",
       "\n",
       "     CI - upper  \n",
       "0 -1.423694e+08  \n",
       "1  2.851622e+05  \n",
       "2  8.589131e+04  \n",
       "3  3.029757e+05  \n",
       "4  8.264832e+04  \n",
       "5  4.353063e+01  \n",
       "6 -3.207006e+04  \n",
       "7 -4.367904e+03  \n",
       "8 -1.174431e+06  \n",
       "9  8.787464e+05  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set a seed for reproducability\n",
    "np.random.seed(1234)\n",
    "\n",
    "# estimate a regression with bootstrap standard errors (here I use the default bootstrap sample size)\n",
    "HP_reg.estimate('bootstrap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, bootstrap does not change our conclusion regarding statistical significance. \n",
    "\n",
    "### 3.2 Implementation with `statsmodels`\n",
    "\n",
    "#### 3.2.1 running the regression with non-robust standard errors\n",
    "Build X and Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the Y, and X matrices\n",
    "Y = np.asarray([housing.Price]).T\n",
    "X = np.asarray(housing.iloc[:,1:])\n",
    "\n",
    "# add a constant to the independent variables\n",
    "X = np.hstack((np.ones([X.shape[0],1]), X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th>  <td>   0.556</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.556</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   1457.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 16 Feb 2022</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:13:25</td>     <th>  Log-Likelihood:    </th> <td>-1.5098e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 10459</td>      <th>  AIC:               </th>  <td>3.020e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 10449</td>      <th>  BIC:               </th>  <td>3.021e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     9</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>-1.542e+08</td> <td> 5.66e+06</td> <td>  -27.238</td> <td> 0.000</td> <td>-1.65e+08</td> <td>-1.43e+08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td> 2.187e+05</td> <td> 1.77e+04</td> <td>   12.355</td> <td> 0.000</td> <td> 1.84e+05</td> <td> 2.53e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td> 2.218e+04</td> <td> 1.78e+04</td> <td>    1.249</td> <td> 0.212</td> <td>-1.26e+04</td> <td>  5.7e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td> 2.742e+05</td> <td> 8392.414</td> <td>   32.677</td> <td> 0.000</td> <td> 2.58e+05</td> <td> 2.91e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td> 6.902e+04</td> <td> 5082.994</td> <td>   13.580</td> <td> 0.000</td> <td> 5.91e+04</td> <td>  7.9e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   30.5028</td> <td>    4.094</td> <td>    7.451</td> <td> 0.000</td> <td>   22.479</td> <td>   38.527</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>-3.416e+04</td> <td>  758.608</td> <td>  -45.027</td> <td> 0.000</td> <td>-3.56e+04</td> <td>-3.27e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>-4969.2049</td> <td>  133.804</td> <td>  -37.138</td> <td> 0.000</td> <td>-5231.487</td> <td>-4706.923</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>-1.269e+06</td> <td> 5.31e+04</td> <td>  -23.896</td> <td> 0.000</td> <td>-1.37e+06</td> <td>-1.17e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td> 8.012e+05</td> <td>  4.1e+04</td> <td>   19.525</td> <td> 0.000</td> <td> 7.21e+05</td> <td> 8.82e+05</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>6799.969</td> <th>  Durbin-Watson:     </th>  <td>   1.694</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>251030.115</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 2.589</td>  <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>26.435</td>  <th>  Cond. No.          </th>  <td>2.66e+06</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.66e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.556\n",
       "Model:                            OLS   Adj. R-squared:                  0.556\n",
       "Method:                 Least Squares   F-statistic:                     1457.\n",
       "Date:                Wed, 16 Feb 2022   Prob (F-statistic):               0.00\n",
       "Time:                        14:13:25   Log-Likelihood:            -1.5098e+05\n",
       "No. Observations:               10459   AIC:                         3.020e+05\n",
       "Df Residuals:                   10449   BIC:                         3.021e+05\n",
       "Df Model:                           9                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const      -1.542e+08   5.66e+06    -27.238      0.000   -1.65e+08   -1.43e+08\n",
       "x1          2.187e+05   1.77e+04     12.355      0.000    1.84e+05    2.53e+05\n",
       "x2          2.218e+04   1.78e+04      1.249      0.212   -1.26e+04     5.7e+04\n",
       "x3          2.742e+05   8392.414     32.677      0.000    2.58e+05    2.91e+05\n",
       "x4          6.902e+04   5082.994     13.580      0.000    5.91e+04     7.9e+04\n",
       "x5            30.5028      4.094      7.451      0.000      22.479      38.527\n",
       "x6         -3.416e+04    758.608    -45.027      0.000   -3.56e+04   -3.27e+04\n",
       "x7         -4969.2049    133.804    -37.138      0.000   -5231.487   -4706.923\n",
       "x8         -1.269e+06   5.31e+04    -23.896      0.000   -1.37e+06   -1.17e+06\n",
       "x9          8.012e+05    4.1e+04     19.525      0.000    7.21e+05    8.82e+05\n",
       "==============================================================================\n",
       "Omnibus:                     6799.969   Durbin-Watson:                   1.694\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           251030.115\n",
       "Skew:                           2.589   Prob(JB):                         0.00\n",
       "Kurtosis:                      26.435   Cond. No.                     2.66e+06\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.66e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the regression\n",
    "model = sm.OLS(Y, X)\n",
    "results = model.fit()\n",
    "\n",
    "# display output table\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Estimating the regression with Bootstrap standard errors\n",
    "\n",
    "First, we need to save the $\\beta$ from the original regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_ = results.params.ravel()[:,None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now write a loop to compute Bootstrap standard errors. To ensure robustness, let's write a small function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bootstrap(Y,X,B=1000):\n",
    "\n",
    "    # initialize the array of bootstrap estimates\n",
    "    bootstrapbeta = np.empty([beta_.shape[0],B])\n",
    "\n",
    "    # compute the coefficients over the bootstrap sample\n",
    "    for i in range(B):\n",
    "\n",
    "        # generate a vector of randomly drawn indices with replacement\n",
    "        random_indices = np.random.choice(Y.shape[0], size=Y.shape[0], replace=True)\n",
    "\n",
    "        # select the corresponding rows of Y and X\n",
    "        Y_b = Y[random_indices]\n",
    "        X_b = X[random_indices]\n",
    "\n",
    "        # run the regression with statsmodels\n",
    "        model = sm.OLS(Y_b, X_b)\n",
    "        results = model.fit()\n",
    "\n",
    "        beta = results.params.ravel()\n",
    "\n",
    "        # collect all bootstrap coefficients\n",
    "        bootstrapbeta[:,i] = beta.ravel()\n",
    "\n",
    "    # compute bootstrap standard errors\n",
    "    se = np.sqrt(np.mean(np.square(bootstrapbeta-beta_),axis=1))[:,None]\n",
    "\n",
    "    #compute the bootstrap confidence intervals\n",
    "    CI_upper = beta_ + 2*se\n",
    "    CI_lower = beta_ - 2*se\n",
    "\n",
    "    # ------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    #compute t-statistic for standard hypothesis test\n",
    "    t = np.abs(beta_/se)\n",
    "\n",
    "    #compute p-values for standard hypothesis test\n",
    "    p_vals = 2*(1-stats.norm.cdf(np.abs(t)))\n",
    "\n",
    "    #generate an output table\n",
    "    outmat = np.concatenate((beta_,se,t,p_vals,CI_lower,CI_upper),axis=1)\n",
    "    table = pd.DataFrame(outmat)\n",
    "    table.columns =['beta', 'se','t-statistic','p-value','CI - lower','CI - upper']\n",
    "    \n",
    "    # return the output table\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the `Bootstrap` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beta</th>\n",
       "      <th>se</th>\n",
       "      <th>t-statistic</th>\n",
       "      <th>p-value</th>\n",
       "      <th>CI - lower</th>\n",
       "      <th>CI - upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.542411e+08</td>\n",
       "      <td>5.935885e+06</td>\n",
       "      <td>25.984526</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.661129e+08</td>\n",
       "      <td>-1.423694e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.187334e+05</td>\n",
       "      <td>3.321442e+04</td>\n",
       "      <td>6.585494</td>\n",
       "      <td>4.533751e-11</td>\n",
       "      <td>1.523045e+05</td>\n",
       "      <td>2.851622e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.218366e+04</td>\n",
       "      <td>3.185383e+04</td>\n",
       "      <td>0.696421</td>\n",
       "      <td>4.861655e-01</td>\n",
       "      <td>-4.152399e+04</td>\n",
       "      <td>8.589131e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.742361e+05</td>\n",
       "      <td>1.436979e+04</td>\n",
       "      <td>19.084214</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.454965e+05</td>\n",
       "      <td>3.029757e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.902475e+04</td>\n",
       "      <td>6.811783e+03</td>\n",
       "      <td>10.133139</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.540118e+04</td>\n",
       "      <td>8.264832e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.050285e+01</td>\n",
       "      <td>6.513893e+00</td>\n",
       "      <td>4.682737</td>\n",
       "      <td>2.830702e-06</td>\n",
       "      <td>1.747506e+01</td>\n",
       "      <td>4.353063e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-3.415782e+04</td>\n",
       "      <td>1.043883e+03</td>\n",
       "      <td>32.721883</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-3.624559e+04</td>\n",
       "      <td>-3.207006e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-4.969205e+03</td>\n",
       "      <td>3.006504e+02</td>\n",
       "      <td>16.528185</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-5.570506e+03</td>\n",
       "      <td>-4.367904e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.269495e+06</td>\n",
       "      <td>4.753209e+04</td>\n",
       "      <td>26.708173</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.364559e+06</td>\n",
       "      <td>-1.174431e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8.011514e+05</td>\n",
       "      <td>3.879750e+04</td>\n",
       "      <td>20.649562</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.235564e+05</td>\n",
       "      <td>8.787464e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           beta            se  t-statistic       p-value    CI - lower  \\\n",
       "0 -1.542411e+08  5.935885e+06    25.984526  0.000000e+00 -1.661129e+08   \n",
       "1  2.187334e+05  3.321442e+04     6.585494  4.533751e-11  1.523045e+05   \n",
       "2  2.218366e+04  3.185383e+04     0.696421  4.861655e-01 -4.152399e+04   \n",
       "3  2.742361e+05  1.436979e+04    19.084214  0.000000e+00  2.454965e+05   \n",
       "4  6.902475e+04  6.811783e+03    10.133139  0.000000e+00  5.540118e+04   \n",
       "5  3.050285e+01  6.513893e+00     4.682737  2.830702e-06  1.747506e+01   \n",
       "6 -3.415782e+04  1.043883e+03    32.721883  0.000000e+00 -3.624559e+04   \n",
       "7 -4.969205e+03  3.006504e+02    16.528185  0.000000e+00 -5.570506e+03   \n",
       "8 -1.269495e+06  4.753209e+04    26.708173  0.000000e+00 -1.364559e+06   \n",
       "9  8.011514e+05  3.879750e+04    20.649562  0.000000e+00  7.235564e+05   \n",
       "\n",
       "     CI - upper  \n",
       "0 -1.423694e+08  \n",
       "1  2.851622e+05  \n",
       "2  8.589131e+04  \n",
       "3  3.029757e+05  \n",
       "4  8.264832e+04  \n",
       "5  4.353063e+01  \n",
       "6 -3.207006e+04  \n",
       "7 -4.367904e+03  \n",
       "8 -1.174431e+06  \n",
       "9  8.787464e+05  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set a seed for reproducability\n",
    "np.random.seed(1234)\n",
    "\n",
    "# run the regression using the bootstrap function\n",
    "Bootstrap(Y,X,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 4.0 Cross-Validation\n",
    "\n",
    "**You can ignore section 4.1 and jump to the implementation with `statsmodels` in section 4.2.**\n",
    "\n",
    "### 4.1 Implementation with own code\n",
    "\n",
    "Let us again write a small function that operates on our class and does CV for us. For k-fold cross-validation, we always use k-1 chunks as training data and the 1 data chunk as testing data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV_OLS(Y, X, k = 10):\n",
    "    # generate arrays containing the indices of the k data chunks\n",
    "    ids = list(range(len(Y)))\n",
    "    chunks = np.asarray(np.array_split(np.array(ids),k))\n",
    "        \n",
    "    # read out the sample size\n",
    "    n = list(range(len(Y)))\n",
    "    \n",
    "    # convert k into a list\n",
    "    a = np.arange(k)\n",
    "    \n",
    "    # initialize out-of-sample and in-sample loss\n",
    "    D_oos = []\n",
    "    D_is = []\n",
    "    MSE_oos = []\n",
    "    MSE_is = []\n",
    "    R2_oos = []\n",
    "    R2_is = []\n",
    "    \n",
    "    \n",
    "    # iterate over the folds to compute the CV standard error\n",
    "    for i in a:\n",
    "        \n",
    "        # obtain the indeces of the data belonging to the training sample\n",
    "        b_train = a[np.arange(len(a))!=i]\n",
    "        subid_train = np.concatenate( chunks[b_train], axis=0 )\n",
    "        \n",
    "        # obtain the indices of the data belonging to the test sample\n",
    "        b_test =  a[np.arange(len(a)) ==i]\n",
    "        subid_test = np.concatenate( chunks[b_test], axis=0 )\n",
    "        \n",
    "        # devide the data into test and training samples\n",
    "        Y_train = Y[subid_train]\n",
    "        X_train = X[subid_train,:]\n",
    "        Y_test = Y[subid_test]\n",
    "        X_test = X[subid_test,:]\n",
    "        \n",
    "        # use the OLS class to estimate the parameters on the training sample\n",
    "        estimate_train = OLS(Y_train,X_train)\n",
    "        estimate_train.estimate()\n",
    "\n",
    "        # compute the out-of-sample error\n",
    "        error_oos = Y_test - X_test @ estimate_train.beta\n",
    "        \n",
    "        # compute the in-sample error\n",
    "        error_is = Y_train - X_train @ estimate_train.beta\n",
    "\n",
    "        # compute DOOS\n",
    "        D_oos.append(np.sum(np.square(error_oos),axis=0))\n",
    "        D_is.append(np.sum(np.square(error_is),axis=0))\n",
    "            \n",
    "        # compute MSE\n",
    "        MSE_oos.append(np.mean(np.square(error_oos),axis=0))\n",
    "        MSE_is.append(np.mean(np.square(error_is),axis=0))\n",
    "        \n",
    "        # compute R^2\n",
    "        R2_oos.append(1 - MSE_oos[-1]/np.var(Y_test))\n",
    "        R2_is.append(1 - MSE_is[-1]/np.var(Y_train))\n",
    "\n",
    "        \n",
    "    # compute the expected out-of-sample and in-sample loss for Deviance \n",
    "    E_D_oos = np.mean(D_oos)\n",
    "    E_D_is = np.mean(D_is)\n",
    "    \n",
    "    # compute the expected out-of-sample and in-sample loss for MSE\n",
    "    E_MSE_oos = np.mean(MSE_oos)\n",
    "    E_MSE_is = np.mean(MSE_is)\n",
    "\n",
    "    # compute the expected out-of-sample and in-sample loss for R2\n",
    "    E_R2_oos = np.mean(R2_oos)\n",
    "    E_R2_is = np.mean(R2_is)\n",
    "    \n",
    "    # compute the CV standard errors for Deviance\n",
    "    se_D_oos = np.sqrt(np.var(D_oos,ddof=1))\n",
    "    se_D_is  = np.sqrt(np.var(D_is,ddof=1))\n",
    "    \n",
    "    # compute the CV standard errors for Deviance\n",
    "    se_MSE_oos = np.sqrt(np.var(MSE_oos,ddof=1))\n",
    "    se_MSE_is  = np.sqrt(np.var(MSE_is,ddof=1))\n",
    "    \n",
    "    # compute the CV standard errors for Deviance\n",
    "    se_R2_oos = np.sqrt(np.var(R2_oos,ddof=1))\n",
    "    se_R2_is  = np.sqrt(np.var(R2_is,ddof=1))\n",
    "    \n",
    "    \n",
    "    # create output table\n",
    "    names = [np.array(['in-sample', 'in-sample', 'in-sample', 'out-of-sample', 'out-of-sample', 'out-of-sample']),\n",
    "              np.array(['Deviance','MSE','R2','Deviance','MSE','R2'])]\n",
    "    outmat = [[E_D_is,se_D_is],[E_MSE_is,se_MSE_is], [E_R2_is,se_R2_is],\n",
    "             [E_D_oos,se_D_oos],[E_MSE_oos,se_MSE_oos], [E_R2_oos,se_R2_oos]]\n",
    "    table = pd.DataFrame(outmat,index=names)\n",
    "    table.columns =['$\\hat{e}$','$se(\\hat{e})$'] \n",
    "    \n",
    "    # return table as output\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# use a cell magic to supress output from the OLS.estimate() class\n",
    "\n",
    "# run cross-validation\n",
    "out = CV_OLS(Y,X,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>$\\hat{e}$</th>\n",
       "      <th>$se(\\hat{e})$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">in-sample</th>\n",
       "      <th>Deviance</th>\n",
       "      <td>1.903003e+15</td>\n",
       "      <td>4.739279e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>2.021654e+11</td>\n",
       "      <td>5.034502e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>5.566360e-01</td>\n",
       "      <td>7.487237e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">out-of-sample</th>\n",
       "      <th>Deviance</th>\n",
       "      <td>2.138766e+14</td>\n",
       "      <td>4.739170e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>2.044899e+11</td>\n",
       "      <td>4.530461e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>5.411131e-01</td>\n",
       "      <td>6.618815e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           $\\hat{e}$  $se(\\hat{e})$\n",
       "in-sample     Deviance  1.903003e+15   4.739279e+13\n",
       "              MSE       2.021654e+11   5.034502e+09\n",
       "              R2        5.566360e-01   7.487237e-03\n",
       "out-of-sample Deviance  2.138766e+14   4.739170e+13\n",
       "              MSE       2.044899e+11   4.530461e+10\n",
       "              R2        5.411131e-01   6.618815e-02"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the output   \n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the $R^2$, we can see that the out-of-sample fit is slightly worse. With our regression, we can explain 56% of in-sample variation and 54% of out-of-sample variation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Implementation with `statsmodels`\n",
    "\n",
    "Let us again write a small function that operates on our class and does CV for us. For k-fold cross-validation, we always use k-1 chunks as training data and the 1 data chunk as testing data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV_OLS(Y, X, k = 10):\n",
    "    # generate arrays containing the indices of the k data chunks\n",
    "    ids = list(range(len(Y)))\n",
    "    chunks = np.asarray(np.array_split(np.array(ids),k))\n",
    "        \n",
    "    # read out the sample size\n",
    "    n = list(range(len(Y)))\n",
    "    \n",
    "    # convert k into a list\n",
    "    a = np.arange(k)\n",
    "    \n",
    "    # initialize out-of-sample and in-sample loss\n",
    "    D_oos = []\n",
    "    D_is = []\n",
    "    MSE_oos = []\n",
    "    MSE_is = []\n",
    "    R2_oos = []\n",
    "    R2_is = []\n",
    "    \n",
    "    \n",
    "    # iterate over the folds to compute the CV standard error\n",
    "    for i in a:\n",
    "        \n",
    "        # obtain the indeces of the data belonging to the training sample\n",
    "        b_train = a[np.arange(len(a))!=i]\n",
    "        subid_train = np.concatenate( chunks[b_train], axis=0 )\n",
    "        \n",
    "        # obtain the indices of the data belonging to the test sample\n",
    "        b_test =  a[np.arange(len(a)) ==i]\n",
    "        subid_test = np.concatenate( chunks[b_test], axis=0 )\n",
    "        \n",
    "        # devide the data into test and training samples\n",
    "        Y_train = Y[subid_train]\n",
    "        X_train = X[subid_train,:]\n",
    "        Y_test = Y[subid_test]\n",
    "        X_test = X[subid_test,:]\n",
    "        \n",
    "        # use the statsmodels to estimate the parameters on the training sample\n",
    "        model = sm.OLS(Y_train, X_train)\n",
    "        results = model.fit()\n",
    "        \n",
    "        # extract the beta coefficients\n",
    "        beta_train = results.params.ravel()[:,None]\n",
    "        \n",
    "        # compute the out-of-sample error\n",
    "        error_oos = Y_test - X_test @ beta_train\n",
    "        \n",
    "        # compute the in-sample error\n",
    "        error_is = Y_train - X_train @ beta_train\n",
    "\n",
    "        # compute DOOS\n",
    "        D_oos.append(np.sum(np.square(error_oos),axis=0))\n",
    "        D_is.append(np.sum(np.square(error_is),axis=0))\n",
    "            \n",
    "        # compute MSE\n",
    "        MSE_oos.append(np.mean(np.square(error_oos),axis=0))\n",
    "        MSE_is.append(np.mean(np.square(error_is),axis=0))\n",
    "        \n",
    "        # compute R^2\n",
    "        R2_oos.append(1 - MSE_oos[-1]/np.var(Y_test))\n",
    "        R2_is.append(1 - MSE_is[-1]/np.var(Y_train))\n",
    "\n",
    "        \n",
    "    # compute the expected out-of-sample and in-sample loss for Deviance \n",
    "    E_D_oos = np.mean(D_oos)\n",
    "    E_D_is = np.mean(D_is)\n",
    "    \n",
    "    # compute the expected out-of-sample and in-sample loss for MSE\n",
    "    E_MSE_oos = np.mean(MSE_oos)\n",
    "    E_MSE_is = np.mean(MSE_is)\n",
    "\n",
    "    # compute the expected out-of-sample and in-sample loss for R2\n",
    "    E_R2_oos = np.mean(R2_oos)\n",
    "    E_R2_is = np.mean(R2_is)\n",
    "    \n",
    "    # compute the CV standard errors for Deviance\n",
    "    se_D_oos = np.sqrt(np.var(D_oos,ddof=1))\n",
    "    se_D_is  = np.sqrt(np.var(D_is,ddof=1))\n",
    "    \n",
    "    # compute the CV standard errors for Deviance\n",
    "    se_MSE_oos = np.sqrt(np.var(MSE_oos,ddof=1))\n",
    "    se_MSE_is  = np.sqrt(np.var(MSE_is,ddof=1))\n",
    "    \n",
    "    # compute the CV standard errors for Deviance\n",
    "    se_R2_oos = np.sqrt(np.var(R2_oos,ddof=1))\n",
    "    se_R2_is  = np.sqrt(np.var(R2_is,ddof=1))\n",
    "    \n",
    "    \n",
    "    # create output table\n",
    "    names = [np.array(['in-sample', 'in-sample', 'in-sample', 'out-of-sample', 'out-of-sample', 'out-of-sample']),\n",
    "              np.array(['Deviance','MSE','R2','Deviance','MSE','R2'])]\n",
    "    outmat = [[E_D_is,se_D_is],[E_MSE_is,se_MSE_is], [E_R2_is,se_R2_is],\n",
    "             [E_D_oos,se_D_oos],[E_MSE_oos,se_MSE_oos], [E_R2_oos,se_R2_oos]]\n",
    "    table = pd.DataFrame(outmat,index=names)\n",
    "    table.columns =['$\\hat{e}$','$se(\\hat{e})$'] \n",
    "    \n",
    "    # return table as output\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# use a cell magic to supress output from the OLS.estimate() class\n",
    "\n",
    "# run cross-validation\n",
    "out = CV_OLS(Y,X,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>$\\hat{e}$</th>\n",
       "      <th>$se(\\hat{e})$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">in-sample</th>\n",
       "      <th>Deviance</th>\n",
       "      <td>1.903003e+15</td>\n",
       "      <td>4.739279e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>2.021654e+11</td>\n",
       "      <td>5.034502e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>5.566360e-01</td>\n",
       "      <td>7.487237e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">out-of-sample</th>\n",
       "      <th>Deviance</th>\n",
       "      <td>2.138766e+14</td>\n",
       "      <td>4.739170e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>2.044899e+11</td>\n",
       "      <td>4.530461e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>5.411131e-01</td>\n",
       "      <td>6.618815e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           $\\hat{e}$  $se(\\hat{e})$\n",
       "in-sample     Deviance  1.903003e+15   4.739279e+13\n",
       "              MSE       2.021654e+11   5.034502e+09\n",
       "              R2        5.566360e-01   7.487237e-03\n",
       "out-of-sample Deviance  2.138766e+14   4.739170e+13\n",
       "              MSE       2.044899e+11   4.530461e+10\n",
       "              R2        5.411131e-01   6.618815e-02"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the output   \n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the $R^2$, we can see that the out-of-sample fit is slightly worse. With our regression, we can explain 56% of in-sample variation and 54% of out-of-sample variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
